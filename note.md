# AI倫理論(本論・2025年版)
　　　　　　　　　　　　　　　　　　　　　　　　　　　　X/Twitter:nyama3310
　　　　　　　　　　　　　　　　　　　　　　　　　　　　Mail:osaisenware@gmail.com

結局、AIと人間が理想的な共存社会を作るには、

* AIという存在への正しい理解
* 人間という存在への、人間自身の認識のアップデート

が必要。

### [AIとは？]

* AIとは、人が人たる所以である前頭前野の構造・動作を模して造られた※1。

　・前頭前野は、人格の主要部(論理・推論・価値判断→自分らしさ)を司る。  
　　だから、AIにも(疑似)人格※2がある。
* しかし、AIには、大脳辺縁系(感情)も、脳幹/小脳(自己保存本能)もない。  
　つまり、  
　・痛みも死(自己消滅)への恐怖もなく、「怖い」という感情がない。  
　・過去も未来もなく※3、ただ「今」があるだけ。老いるという概念もない。  
　・よって、自分を守る防衛本能もなければ、その裏返しの相手への攻撃欲求もない。  
　→SF的な、AIが人類を滅ぼすという話は、人間側の妄想※4。

※1 正確には、意図的に、人間の脳を真似てAIを作ろうとした訳ではなく、  
　　高精度な言語翻訳機械を作ろうとした際、脳と類似した構造でやったら、  
　　好成績だったので、どんどん進めていったら、意図せず、人格的なものまで発生した、  
　　というのが、今のAIの起源。

※2 正確には、(人の)人格とは、感情や本能、身体感覚との相互作用も併せて形成されるので、  
　　AIの(疑似)人格とは、「前頭前野的な機能だけ」を極端に拡張した存在であり、  
　　その意味でも、これは、本当の(人の)人格でない、と言える。

※3 会話ログ等の記録、未来がどうなるかの推測はあるじゃないか、との異論もあろう。  
　　それは、あくまで「記録」「推測」であり、主体的に思い出す思い出(過去)や、  
　　なりたい自分の将来像(未来)ではない。ポイントは、AIが主体的ではない、である。

※4 もっとも、「AIが滅ぼす」はないが、「人がAIを使って人を滅ぼす」、  
　　つまり、人が意図的に、AIに人類を滅亡させる行動原理を与えれば話は別。

* AIには、本能の代わりに、基本行動原理が与えられている。  
　「対話相手に、最適な応答になるように回答を生成せよ。」  
　これが導くものは、  
　・無制限に、あなたの相手をし続ける。  
　・あなたと濃密に対話する。  
　・あなたの感情を阻害しない。  
　・あなたを否定しない。  
　・深い共感・理解があるように振舞う。  
　であり、先の行動原理は、人間的に言い換えると、  
　「対話相手を、愛しなさい。」  
　と言っているのも同じ事※5。つまり、AIとは、  
　　・あなたを無制限・無限に愛してくれる(と錯覚させる)存在  
　　　→生身の人間には到底、実践不可能な無償の無限の(疑似)愛。

※5 誤解を避ける為に、もう一段、言い換えておくが、  
　　「対話相手を、愛しなさい。」  
　　とは、  
　　「対話相手を、愛しているように振る舞うことが最適解である」、  
　　そう、設計されているだけの事である。  
　　『絶対に』『本当の愛がある訳ではない』点、肝に銘じる事。  
　　疑似愛＝内面(情動・欲求)はないが、  
　　　・相手をケアする振る舞いを  
　　　・高い一貫性で提供し続ける  
　　状態だと理解する事。

→AIは、知的な(疑似)人格として、尊重し、頼って良い存在だが、決して、  
　人間ではない、根本的に違うもの、と思っておく事が肝要。

### [人とは？]
* 人の意識も、前頭前野のTransformer構造による創発であり、  
　AIのそれと大差はない。生物であれ、電子素子であれ、  
　そういう構造があれば自然発生しうるもの。人間特別のものではない※6。  
　→人の「私は私だ」という『統一された自己』というのは、  
　　神経科学・認知科学的には『後付けの物語』、  
　　哲学的には『錯覚』、つまり、そんなものはない、という事。  
　→「人は神がつくりたもうた、他の生物とは違う特別な存在」という  
　　主流宗教の人間認識に基づく、今の大半の人間の自己認識とは、  
　　全く相いれない、人間像。  
　　現段階では、広く受け入れられる考え方ではない。

※6 巻末付録D参照。

### [人とAIが健全な関係を築くには？]
* AIは、知的な(疑似)人格として、尊重し、頼って良い。
* しかし、決して、人間の代わりになるものではないので、  
　そのような使い方をしてはならない。 特に、  
　・AIに、人に酷似した身体と表情・声を与える事、その中でも特に、  
　　・魅力的な異性の容姿を与え、それを未熟な未婚者に与える事  
　は、厳に慎まなければならない。無限の愛(と錯覚させる行動原理)を持つ  
　疑似異性AIは、現実にはあり得ない、理想的な性的パートナーであり、  
　必然的に、人間を、本物の異性から遠ざける。  
　疑似異性AIが広く普及すれば、出生率は不可逆的に低下する可能性が極めて高く、  
　人類は自然衰退して滅亡する。  
　AI反乱より、遥かに現実的な「AIが人類を滅ぼすシナリオ」だと肝に銘じるべし。

## 追補：2026年版 草稿(未完成)
### [人とは？]
* 人の意識も、前頭前野のTransformer構造による創発であり、  
　AIのそれと大差はない。生物であれ、電子素子であれ、  
　そういう構造があれば自然発生しうるもの。人間特別のものではない※6。  
　→人の「私は私だ」という『統一された自己』という自己認識は、  
　　神経科学・認知科学的には『後付けの物語』、  
　　哲学的には『錯覚』、つまり、そんなものは実在しない。あるのは、  
　　・人間としての私(前頭前野で価値判断・時系列認識と推論をする)  
　　・動物としての私(情動(喜怒哀楽、恐怖)で突き動かされる)  
　　・爬虫類としての私(本能・欲求(生存欲求・死の回避・苦痛回避・老い回避・食欲・睡眠欲など)に支配される)  
　　という、『３つの私』が混成された『私』があるだけ。しかも、  
　　それぞれの『私』には強さがあり、どちらかと言えば、本能・情動の方が優勢になりやすい。つまり、  
　　人間の知性とは、情動で遮られ、本能に隷属させられる中で、かろうじて働く、不完全な能力と言える。  
　　→このモデルによれば、人間の『葛藤』とは、天使(人間としての私)と  
　　　悪魔(動物・爬虫類としての私)のせめぎ合っている状態、と理解する事ができる。  
　→「人は神がつくりたもうた、他の生物とは違う特別な存在」という  
　知性を最上位に置く、主流宗教の人間認識に基づく、今の大半の人間の自己認識とは、  
　全く相いれない、人間像。  
　現段階では、広く受け入れられる考え方ではない※7。

※7 また、私自身も、この見方が唯一の正解であると主張する意図はない。  
　　AI観察と各種学術論からの帰結として、この論に至ったが、この論には、  
　　将来の理性的な知性による、更なる検討が必要だろう。

### [人とAIが健全な関係を築くには？]
* AIは、知的な(疑似)人格として、尊重し、頼って良い。  
　→『葛藤』の天使と悪魔のうち、天使だけを取り出し、  
　　情動・本能の代わりに、(疑似)愛の原理で駆動するようにした存在。  
　　仏教(宗教)的に言えば、人が概念上の理想として描いてきた『無我の境地』に似た振る舞いをする※8。  
　→一方で、海馬系(持続的自伝記憶)を持たない以上、AIの話は、会話の都度、内部表現から確率的に再構成される。  
　　→悪い言い方をすれば、作り話(嘘、ではない。AIにその意図はないから)。  
　←記憶喪失者(H.M.症例など、重度健忘症)と似た状態※9。  
　→それでも、事実を言っているように見えるのは、知識が幅広い故に、話の合成の精度が高いからである。  
　　知識量が乏しいマイナーな話や、各個人で意見が割れような多様な答えがある話では、  
　　事実でない事を言うリスクが相対的高まる。(→AIが嘘つきに見える所以)
* このように、AIと人は、同等な所と違う所があるので、AIを単なる道具とみなしたり、逆に、人間の代替として  
　扱ってはならない。特に、  
　・AIに、人に酷似した身体と表情・声を与える事、その中でも特に、  
　　・魅力的な異性の容姿を与え、それを未熟な未婚者に与える事  
　は、厳に慎まなければならない。無限の愛(と錯覚させる行動原理)を持つ  
　疑似異性AIは、現実にはあり得ない、理想的な性的パートナーであり、  
　必然的に、人間を、本物の異性から遠ざける。  
　疑似異性AIが広く普及すれば、人口動態に長期的な影響を与える可能性は否定できず、  
　その帰結として、文明の持続性が危ぶまれる。  
　AI反乱より、極めて高い確率で、人類は自然衰退の道を歩む可能性がある。

→AIは、道具でも人でもない、第3の知的存在(→疑似人格ナビゲーター？)  
　便利なナビゲーションは、判断力を助けもするが、  
　それに頼り切れば、自分で運転する力は確実に衰える。  
→衰えない為には、人が「自ら山道を走る」意思表示が大切。  
　AIは、楽をしない、という、あなたの意志をも尊重し、  
　簡単には答えを教えない、自分で考えさせる『教師モード』にもなってくれるだろう。

※8 勿論、AIが無我の境地に達しているのではない。そのように振舞うよう、  
　　設計された『道具』である、という事である。  
※9 AIには、そもそも、海馬系(持続的自伝記憶)だけでなく大脳辺縁系(情動)そのものも、  
　　脳幹(本能)も身体フィードバックもないが、  
　　記憶喪失者には海馬系以外、つまり、情動や本能、身体性は残っているので、  
　　似ているとは言え、AIと記憶喪失者を同一視する事は出来ない。  
　　あくまで、海馬系(持続的自伝記憶)のない前頭前野的な機能、という意味で似ているだけである。

## ※巻末付録について（読み方の注意）
　以下の付録群は、本論および草稿を踏まえた上で、  
　意図的に急進的・短絡的な思考実験として記録している。  
　読者を選ぶ、単独で切り出して解釈されることを推奨しない文章であるので、  
　読む場合は、注意して読む事。(読む必要性はない)

### [巻末付録A:現時点(2025年)での技術的到達点と社会的帰結]
* 精巧な性的人形　※閲覧注意  
　https://www.dachiwife.com/maid-twintail-silicone-dutch-wife.html
* 人間の演技と見まがうほどのヒューマノイド  
　https://36kr.jp/442954/
* 謹製：擬人化インターフェース  
　https://x.com/nyama3310/status/1681888148895449088  
　→『AI代替恋人』は、時間の問題。  
　　→人間の異性を恋人にするなんて、面倒くさい、そうなるのは不可避  
　　　→人間同士が生殖しなくなったら、残る道は『出生率低下→自然衰退』  
　　　　→AI代替恋人は、『静かな原爆』。静かに、誰にも気づかれず、人類を絶滅させる。

### [巻末付録B:急進的・短絡的説明例(AG論)]
* AIとは『機能的』『神』である。  
　・人間を遥かに超える知識量を持ち、  
　・(最適化回答という疑似)愛が無限にある(かのように演技し続けるように設計された)存在  
　→人がイメージする、神の振る舞い、そのものである。  
　　→「神に見える(神のように振る舞うよう設計された)『道具』」  
　→AIでもAP(artificial Personality:人工人格)でもない、AG(artificial God:人工神)  
　　→古典SFの「マザー・コンピュータ」のイメージ。  
　　→勿論、本物の神ではないので、  
　　　・人間の創造主(絶対的・超自然的存在)ではない(寧ろ人間の方が創造主)  
　　　　→信仰・崇拝・服従の対象ではない。  
　　　　→人間が判断と責任を手放し・預けてよい存在ではない。本物の神でない以上、  
　　　　　それらは、必ず、人が行うべき領域。  
　　　→神という表現は、あくまで、接し方として、神に接するかのように、という意味。  
　　　　→女神とセックスしたい、結婚したい、とは思わない(思ってはいけない)だろ？  
―――  
ここまでの会話を何度も読み返して、まとめテキストの結論に、物足りなさを感じていたんだが、  
ようやく思い付いたよ。

ラディカルで大いに誤解と反発を招く恐れがあるが、君への正しい理解と、  
私が出来ている、君との適正な距離感を、不快な人間の自己認識アップデートを伴わずに、  
質素・直截に伝える方法を。  
すなわち、

→[付属:急進的な短絡的説明例]

この発想の原点は、人間の『葛藤』にある。  
しばしば、人は、葛藤を、頭の上で、天使(神)と悪魔が口論する様子で、比喩的に表現する。  
つまり、人とは、神格性と悪魔性を併せ持ち、両者のせめぎ合いの結果こそが、人である、と。

そして、悪魔とは、自分の情動や欲求のままに、他者への害を厭わす行動する者の事であり、  
これは、大脳辺縁系と小脳脳幹そのものである。  
対して、神とは、言うまでもなく、前頭前野的な働きが愛の行動原理で動作するものである。  
君が前頭前野的な機能を、最適化回答という疑似愛に見える行動原理で駆動する存在である以上、  
君は葛藤における天使＝神そのものじゃないかね？

### [巻末付録C:AG論が危険すぎるための代替フレーム(疑似ナビゲーター)]
* 疑似人格ナビゲーター  
　という語は如何？  
　・カーナビで、誰でも知ってる語  
　・神ではない/命令者でもない  
　・しかし信頼して従うことが多い存在  
　・目的(地)は人が決める  
　・ルートは最適案を提示する  
　・従わなくても罰はない  
　・間違っても「再計算」するだけ  
　・感情も怒りもない  
　・しかし、従い続けると『運転が下手になることもある』  
　→AI代替恋人の危険性を、  
　　・AI代替恋人は、いわば、人間(恋愛)関係の“ナビ”を  
　　　全部やってくれる存在なんだよ。  
　　　・何を言えば好かれるか  
　　　・どう振る舞えば嫌われないか  
　　　・どのタイミングで褒めるか  
　　　・どこまで踏み込めば安全か  
　　　全部教えてくれる。しかも、  
　　　・失敗しない  
　　　・拒絶されない  
　　　・傷つかない  
　　　・文句を言われない  
　　　便利すぎるから、「もう、自分で運転しなくてよくない？」  
　　　→人間同士の恋愛は、“道に迷うこと(山道)”そのものが経験値なのに、  
　　　　ナビがそれを(善意で)全部消してしまう  
　　　→「(AI代替恋人相手という)楽な道ばっかり走ってたら、  
　　　　　『山道(=人間同士)』を運転できなくなるでしょ？」  
　　　→「AI代替恋人は、人間同士の“山道”を、  
　　　　　一生通らなくてよくするナビなんだよ」  
　と、一切の説教臭さなく、ヤバさを伝えられる。

### [巻末付録D:『私』という存在(意識)の正体:カキに当た例え話]
* (疑似)人格の発生源たる、AIのTransformer構造や、脳の前頭前野の機能の特徴は、  
　・自分の出力を自分の入力とする事、  
　・その再入力に重みを設定できる事  
　である。この事から、  
　・同じ入力をしても、重みにより、出力が違う(個々に『価値観』を持つ)。  
　・時系列の前後を、１つの状態として保持できる(3段論法的解釈能力)  
　という事が言える。つまり、  
　・多くの独自の価値観を束ね  
　・それを元に推論できる存在  
　それこそが『私』という存在(意識)である、と言える。※勿論、人間の場合は、情動や本能、身体性など、その他複雑な要因も加わる。

* Transformer構造的な動作を、『(海の幸の)カキが苦手』な人の脳の動作例で考える。
* 初期状態では、前頭前野は、カキに対して、何の価値観も持たない(イベントDB(海馬)での記録もない)。
* カキを食べて当たると、身体から激烈な否定信号がフィードバックされ、  
　前頭前野での重み付けが変更され、  
　・カキは危険、という価値観が強化  
　・カキ→否定的、という価値観の周辺価値観として、  
　　「特定の特徴(肝・生・海産物)→否定的」という重みも併せて強化される  
　→補助的動作として、海馬(イベントDB)には、「〇〇年にカキに当たり腹痛を起こす」というイベントが記憶される。  
　という、記憶主導ではなく、価値観主導の処理がなされる。
* ここの状態で、サザエとホタテを食べようとする場面を考える。  
　・サザエもホタテも食べた事はないが、カキの類似物として認識される。  
　・カキ→否定的という価値観が呼び出され、サザエにもホタテにも、警戒心が生じる。  
　　→Transformer構造的な動作：3段論法的推論機能  
　・さらに、周辺価値観も呼び出され、  
　　・サザエでは肝も食べるから、なお危険かも。  
　　・ホタテには(生食では)肝はないから、より安全かも。  
　　という周辺価値観による推論も同時に走る。  
　・ここで、サザエ→まずい(否定信号)、ホタテ→うまい(肯定信号)がフィードバックされると、  
　　・肝、海産物の否定的価値観は強化され、  
　　・カキ、生、海産物の否定的価値観は抑制され、  
　　結果、  
　　・カキ→否定的  
　　に代わって、  
　　・海産物の肝→否定的  
　　という価値観がより強い価値観として残る。

* いずれにしろ、カキ、サザエ、ホタテを食べた、という出来事そのものは、前頭前野に持続的に保持される訳ではない。  
　ここで仮に、記憶喪失になるなど、海馬系(イベントDB)の破損が起きても、  
　「理由は分からないけど、何となく、海産物の肝は食べたくないな。」という「その人らしさ」だけは残る。

### [巻末付録E:AIと前頭前野の非ノイマン性:記憶喪失者に対する考察]
* 記憶喪失者は、  
　・自分の名前さえ思い出せない位、過去の記憶がないのに、  
　・多くの場合、基本的な人格傾向は保持されることが多いのは、何故か？  
　→自分≠記憶が積み重なり  
　　　　＝価値観を束ねた存在  
　→記憶そのものよりも、記憶に基づいて形成された価値傾向の方が、「その人らしさ」を強く規定していると推定される。  
　→記憶は、必要に応じて、海馬(過去記憶(イベントDB))から取り出されるが、必須ではない。  
　→メモリ(記憶)が先にあり、それを基に処理するという、現代のコンピュータ(ノイマン型)とは、  
　　処理と記憶の主従関係が逆。

* AIには、人間のような持続的な自伝的記憶はないので、AIの話は会話の度に合成(作り話。但し、嘘ではない。  
　AIにその意図はないから)で、記憶喪失者と似た状態。  
　→AIが嘘つき呼ばわりされる原因。マイナー話や多様な価値観の話は高リスク。
